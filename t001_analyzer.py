#!/usr/bin/env python3
"""
T001: compare_report.csvè©³ç´°åˆ†æãƒ„ãƒ¼ãƒ«

Typeæ¨å®šã®å•é¡Œã‚’è©³ç´°ã«èª¿æŸ»ã—ã€ä¿®æ­£æ–¹é‡ã‚’æ±ºå®šã™ã‚‹
"""

import pandas as pd
import os
import numpy as np
from config import OUTPUT_DIR

def analyze_compare_report():
    """compare_report.csvã®è©³ç´°åˆ†æã‚’å®Ÿè¡Œ"""
    
    print(" T001: compare_report.csv è©³ç´°åˆ†æé–‹å§‹")
    print("=" * 60)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    compare_file = os.path.join(OUTPUT_DIR, 'compare_report.csv')
    if not os.path.exists(compare_file):
        print(f" compare_report.csvãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {compare_file}")
        return
    
    df = pd.read_csv(compare_file, encoding='utf-8')
    
    # åŸºæœ¬æƒ…å ±
    print(f" åŸºæœ¬æƒ…å ±")
    print(f"  ç·ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°: {len(df):,}")
    print(f"  å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {df['File'].nunique()}")
    print(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯åˆ—åæ•°: {df['Column'].nunique()}")
    print()
    
    # é‡å¤§ãªå•é¡Œï¼šActual_Typeã®èª¿æŸ»
    print(f" é‡å¤§ãªå•é¡Œç™ºè¦‹")
    print(f"  Actual_Type ã®åˆ†å¸ƒ:")
    actual_types = df['Actual_Type'].value_counts()
    for dtype, count in actual_types.items():
        print(f"    {dtype}: {count:,} ({count/len(df)*100:.1f}%)")
    print()
    
    if len(actual_types) == 1 and 'TEXT' in actual_types.index:
        print("    å…¨ã¦ã®Actual_TypeãŒTEXTã«ãªã£ã¦ã„ã¾ã™ï¼")
        print("   å‹æ¨å®šãƒ­ã‚¸ãƒƒã‚¯ã«è‡´å‘½çš„ãªå•é¡ŒãŒã‚ã‚Šã¾ã™")
        print()
    
    # å‹ä¸€è‡´ç‡ã®è©³ç´°
    print(f" å‹ä¸€è‡´çŠ¶æ³")
    match_dist = df['Match'].value_counts()
    total = len(df)
    match_rate = (df['Match'] == 'â—‹').sum() / total * 100
    print(f"  ä¸€è‡´: {match_dist.get('â—‹', 0):,} ({match_dist.get('â—‹', 0)/total*100:.1f}%)")
    print(f"  ä¸ä¸€è‡´: {match_dist.get('Ã—', 0):,} ({match_dist.get('Ã—', 0)/total*100:.1f}%)")
    print(f"  ä¸€è‡´ç‡: {match_rate:.1f}%")
    print()
    
    # æ¨å®šå‹ã®åˆ†å¸ƒ
    print(f" æ¨å®šå‹ã®åˆ†å¸ƒ")
    inferred_dist = df['Inferred_Type'].value_counts()
    for dtype, count in inferred_dist.items():
        print(f"  {dtype}: {count:,} ({count/len(df)*100:.1f}%)")
    print()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥åˆ†æ
    print(f" ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥åˆ†æï¼ˆä¸Šä½10ä»¶ï¼‰")
    file_analysis = df.groupby('File').agg({
        'Column': 'count',
        'Match': lambda x: (x == 'â—‹').sum(),
        'Encoding': lambda x: x.iloc[0],
        'Delimiter': lambda x: x.iloc[0]
    }).rename(columns={'Column': 'total_fields', 'Match': 'matched_fields'})
    
    file_analysis['match_rate'] = file_analysis['matched_fields'] / file_analysis['total_fields'] * 100
    file_analysis = file_analysis.sort_values('match_rate')
    
    print("  ãƒ¯ãƒ¼ã‚¹ãƒˆ10ãƒ•ã‚¡ã‚¤ãƒ« (ä¸€è‡´ç‡é †):")
    for file, row in file_analysis.head(10).iterrows():
        print(f"    {file[:30]:30} | {row['matched_fields']:3}/{row['total_fields']:3} ({row['match_rate']:5.1f}%) | {row['Encoding']} | {row['Delimiter']}")
    print()
    
    # å‹ä¸ä¸€è‡´ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°
    print(f" å‹ä¸ä¸€è‡´ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°")
    mismatch_df = df[df['Match'] != 'â—‹']
    if len(mismatch_df) > 0:
        patterns = mismatch_df.groupby(['Inferred_Type', 'Actual_Type']).size().sort_values(ascending=False)
        print("  ä¸»è¦ãªä¸ä¸€è‡´ãƒ‘ã‚¿ãƒ¼ãƒ³:")
        for (inferred, actual), count in patterns.head(15).items():
            print(f"    {inferred:12}  {actual:12}: {count:4,} ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ ({count/len(mismatch_df)*100:5.1f}%)")
    print()
    
    # SAPãƒ‡ãƒ¼ã‚¿ç‰¹æ®Šãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
    print(f" SAPãƒ‡ãƒ¼ã‚¿ç‰¹æ®Šãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º")
    # 0ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°å¯èƒ½æ€§
    zero_padding_candidates = df[
        (df['Column'].str.contains('CODE|CD|NO|NUM', case=False, na=False)) &
        (df['Inferred_Type'] == 'TEXT')
    ]
    print(f"  0ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°å€™è£œ: {len(zero_padding_candidates)} ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰")
    
    # å¾Œã‚ãƒã‚¤ãƒŠã‚¹å¯èƒ½æ€§ï¼ˆæ•°å€¤ã ãŒæ¨å®šãŒTEXTã®ã‚‚ã®ï¼‰
    minus_candidates = df[
        (df['Inferred_Type'] != 'TEXT') & 
        (df['Actual_Type'] == 'TEXT')
    ]
    print(f"  å¾Œã‚ãƒã‚¤ãƒŠã‚¹å€™è£œ: {len(minus_candidates)} ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰")
    print()
    
    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ»åŒºåˆ‡ã‚Šæ–‡å­—åˆ†æ
    print(f" ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼åˆ†æ")
    print("  ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°åˆ†å¸ƒ:")
    enc_dist = df['Encoding'].value_counts()
    for enc, count in enc_dist.items():
        unique_files = df[df['Encoding'] == enc]['File'].nunique()
        print(f"    {enc:10}: {count:4,} ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ ({unique_files} ãƒ•ã‚¡ã‚¤ãƒ«)")
    
    print("  åŒºåˆ‡ã‚Šæ–‡å­—åˆ†å¸ƒ:")
    delim_dist = df['Delimiter'].value_counts()
    for delim, count in delim_dist.items():
        unique_files = df[df['Delimiter'] == delim]['File'].nunique()
        delim_display = repr(delim) if delim in ['\t', '\n', '\r'] else delim
        print(f"    {delim_display:10}: {count:4,} ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ ({unique_files} ãƒ•ã‚¡ã‚¤ãƒ«)")
    print()
    
    # é‡è¤‡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã®æ¤œå‡º
    print(f" é‡è¤‡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã®æ¤œå‡º")
    column_counts = df['Column'].value_counts()
    duplicates = column_counts[column_counts > 1]
    
    print(f"  é‡è¤‡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åæ•°: {len(duplicates)}")
    if len(duplicates) > 0:
        print("  ä¸Šä½é‡è¤‡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰:")
        for col, count in duplicates.head(10).items():
            files_with_col = df[df['Column'] == col]['File'].nunique()
            print(f"    {col:30}: {count:3} å›å‡ºç¾ ({files_with_col} ãƒ•ã‚¡ã‚¤ãƒ«)")
    print()
    
    # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    print(f" æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    print("  1.  ç·Šæ€¥: Actual_Typeæ¨å®šãƒ­ã‚¸ãƒƒã‚¯ã®ä¿®æ­£")
    print("      analyzer.py ã®å‹æ¨å®šé–¢æ•°ã‚’ç¢ºèª")
    print("      å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã§ãƒ†ã‚¹ãƒˆ")
    print()
    print("  2.  SAPãƒ‡ãƒ¼ã‚¿ç‰¹æ®Šãƒ«ãƒ¼ãƒ«ã®å®Ÿè£…")
    print(f"      0ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°å€™è£œ: {len(zero_padding_candidates)} ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰")
    print(f"      å¾Œã‚ãƒã‚¤ãƒŠã‚¹å€™è£œ: {len(minus_candidates)} ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰")
    print()
    print("  3.  é‡è¤‡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®çµ±åˆè¨ˆç”»")
    print(f"      é‡è¤‡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {len(duplicates)} ç¨®é¡")
    print()
    print("  4. ğŸ§ª æ®µéšçš„ä¿®æ­£ã®å®Ÿæ–½")
    print("      ã¾ãš1ãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ†ã‚¹ãƒˆ")
    print("      æˆåŠŸå¾Œã«å…¨ä½“é©ç”¨")
    
    print("\n" + "=" * 60)
    print(" T001åˆ†æå®Œäº† - æ¬¡ã®ã‚¿ã‚¹ã‚¯: analyzer.py ã®å‹æ¨å®šãƒ­ã‚¸ãƒƒã‚¯èª¿æŸ»")


if __name__ == "__main__":
    analyze_compare_report()
