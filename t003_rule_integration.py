#!/usr/bin/env python3
"""
T003 - ãƒ«ãƒ¼ãƒ«çµ±åˆã‚·ã‚¹ãƒ†ãƒ 
pattern_rules.py ã¨ loader.py ã®çµ±åˆæ©Ÿèƒ½
GUIæ“ä½œã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åæ˜ ã¾ã§ã®ä¸€è²«æ€§ç¢ºä¿
"""

import json
from pathlib import Path
from typing import Dict, List, Any
import sqlite3
from config import DB_FILE
import pattern_rules

class RuleIntegrationManager:
    """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ«ãƒ¼ãƒ«ç®¡ç†ã¨loader.pyçµ±åˆã®ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, pattern_rules_manager: pattern_rules.TypeCorrectionRules = None):
        self.pattern_rules = pattern_rules_manager or pattern_rules.TypeCorrectionRules()
        self.loader_updates_file = "t002_loader_updates.json"
        
    def generate_loader_updates_from_rules(self) -> Dict[str, Any]:
        """pattern_rules.pyã®ãƒ«ãƒ¼ãƒ«ã‹ã‚‰t002_loader_updates.jsonå½¢å¼ã‚’ç”Ÿæˆ"""
        
        loader_updates = {
            "datetime_override_fields": [],
            "storage_code_fields": [],
            "total_overrides": 0
        }
        
        # 1. æœªç™»éŒ²ãƒ•ã‚¡ã‚¤ãƒ«ãƒ«ãƒ¼ãƒ«ã‹ã‚‰å¼·åˆ¶TEXTåŒ–ã‚’ç”Ÿæˆ
        unregistered_files = self.pattern_rules._rules_data.get('unregistered_files', {})
        
        # 2. ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ãƒ«ãƒ¼ãƒ«ã‹ã‚‰å‹ä¿®æ­£ã‚’ç”Ÿæˆ
        business_rules = self.pattern_rules._rules_data.get('business_logic_rules', {})
        
        # ã‚³ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆä¿ç®¡å ´æ‰€ãªã©ï¼‰ã‚’å¼·åˆ¶TEXTåŒ–
        code_fields = business_rules.get('code_fields', [])
        if 'ä¿ç®¡å ´æ‰€' in code_fields:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ä¿ç®¡å ´æ‰€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŒã¤ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
            storage_files = self._get_files_with_field('ä¿ç®¡å ´æ‰€')
            for file_name in storage_files:
                loader_updates["storage_code_fields"].append({
                    "file": file_name,
                    "field": "ä¿ç®¡å ´æ‰€", 
                    "action": "force_text"
                })
        
        # 3. æ—¥ä»˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰å•é¡Œã®ã‚ã‚‹DATETIMEãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å¼·åˆ¶TEXTåŒ–
        datetime_patterns = self.pattern_rules._rules_data.get('datetime_patterns', [])
        
        # æ—¢çŸ¥ã®å•é¡ŒDATETIMEãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ 
        problematic_datetime_fields = [
            {"file": "GetSekkeiWBSJisseki.txt", "field": "COMP_SCH_DT"},
            {"file": "zs45.txt", "field": "TecComp"}, 
            {"file": "ZS61KDAY.csv", "field": "å·¥å ´å‡ºåº«å¯èƒ½æ—¥"},
            {"file": "ZS61KDAY.csv", "field": "å·¥å ´å›ç­”æ—¥"}
        ]
        
        for field_info in problematic_datetime_fields:
            loader_updates["datetime_override_fields"].append({
                **field_info,
                "action": "force_text"
            })
            
        # 4. ç·æ•°ã‚’è¨ˆç®—
        loader_updates["total_overrides"] = (
            len(loader_updates["datetime_override_fields"]) + 
            len(loader_updates["storage_code_fields"])
        )
        
        return loader_updates
    
    def _get_files_with_field(self, field_name: str) -> List[str]:
        """æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã‚’æŒã¤ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        try:
            conn = sqlite3.connect(DB_FILE)
            cursor = conn.cursor()
            
            # column_masterã‹ã‚‰è©²å½“ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŒã¤ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            cursor.execute(
                "SELECT DISTINCT file_name FROM column_master WHERE column_name = ?", 
                (field_name,)
            )
            
            files = [row[0] for row in cursor.fetchall()]
            conn.close()
            return files
            
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ {field_name} ã‚’æŒã¤ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ä¸­: {e}")
            return []
    
    def update_loader_updates_file(self) -> bool:
        """ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦t002_loader_updates.jsonã‚’æ›´æ–°"""
        try:
            loader_updates = self.generate_loader_updates_from_rules()
            
            with open(self.loader_updates_file, 'w', encoding='utf-8') as f:
                json.dump(loader_updates, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… {self.loader_updates_file} ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
            print(f"   - DATETIMEä¿®æ­£: {len(loader_updates['datetime_override_fields'])}ä»¶")
            print(f"   - ä¿ç®¡å ´æ‰€ä¿®æ­£: {len(loader_updates['storage_code_fields'])}ä»¶") 
            print(f"   - ç·ä¿®æ­£æ•°: {loader_updates['total_overrides']}ä»¶")
            
            return True
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: loaderæ›´æ–°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆä¸­: {e}")
            return False
    
    def sync_gui_to_loader(self) -> bool:
        """GUIã®å¤‰æ›´ã‚’loader.pyã«å³åº§ã«åæ˜ """
        success = self.update_loader_updates_file()
        
        if success:
            print("ğŸ”„ GUIè¨­å®šãŒloader.pyã«åæ˜ ã•ã‚Œã¾ã—ãŸ")
            print("ğŸ’¡ å¤‰æ›´ã‚’é©ç”¨ã™ã‚‹ã«ã¯ 'python loader.py' ã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„")
        
        return success
    
    def get_current_rule_status(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®ãƒ«ãƒ¼ãƒ«é©ç”¨çŠ¶æ³ã‚’å–å¾—"""
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ«ãƒ¼ãƒ«ã®çŠ¶æ³
        pattern_status = {
            "unregistered_files": len(self.pattern_rules._rules_data.get('unregistered_files', {})),
            "datetime_patterns": len(self.pattern_rules._rules_data.get('datetime_patterns', [])),
            "code_fields": len(self.pattern_rules._rules_data.get('business_logic_rules', {}).get('code_fields', [])),
            "amount_fields": len(self.pattern_rules._rules_data.get('business_logic_rules', {}).get('amount_fields', [])),
            "quantity_fields": len(self.pattern_rules._rules_data.get('business_logic_rules', {}).get('quantity_fields', []))
        }
        
        # loaderæ›´æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã®çŠ¶æ³
        loader_status = {"exists": False, "total_overrides": 0}
        if Path(self.loader_updates_file).exists():
            try:
                with open(self.loader_updates_file, 'r', encoding='utf-8') as f:
                    loader_data = json.load(f)
                    loader_status = {
                        "exists": True,
                        "total_overrides": loader_data.get("total_overrides", 0),
                        "datetime_overrides": len(loader_data.get("datetime_override_fields", [])),
                        "storage_overrides": len(loader_data.get("storage_code_fields", []))
                    }
            except Exception as e:
                print(f"è­¦å‘Š: loaderæ›´æ–°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        return {
            "pattern_rules": pattern_status,
            "loader_updates": loader_status,
            "sync_required": not loader_status["exists"] or loader_status["total_overrides"] == 0
        }

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=== T003 ãƒ«ãƒ¼ãƒ«çµ±åˆã‚·ã‚¹ãƒ†ãƒ  ===")
    
    # ãƒ«ãƒ¼ãƒ«çµ±åˆç®¡ç†å™¨ã‚’åˆæœŸåŒ–
    manager = RuleIntegrationManager()
    
    # ç¾åœ¨ã®çŠ¶æ³ã‚’ç¢ºèª
    print("\nğŸ“Š ç¾åœ¨ã®ãƒ«ãƒ¼ãƒ«çŠ¶æ³:")
    status = manager.get_current_rule_status()
    
    print(f"Pattern Rules:")
    for key, value in status["pattern_rules"].items():
        print(f"  - {key}: {value}ä»¶")
    
    print(f"Loader Updates:")
    for key, value in status["loader_updates"].items():
        print(f"  - {key}: {value}")
    
    # åŒæœŸãŒå¿…è¦ãªå ´åˆã¯å®Ÿè¡Œ
    if status["sync_required"]:
        print("\nğŸ”„ åŒæœŸãŒå¿…è¦ã§ã™ã€‚loaderæ›´æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆä¸­...")
        manager.sync_gui_to_loader()
    else:
        print("\nâœ… ãƒ«ãƒ¼ãƒ«ã¯æ—¢ã«åŒæœŸã•ã‚Œã¦ã„ã¾ã™")
    
    print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
    print("1. Streamlitã§GUIæ“ä½œã‚’è¡Œã†")
    print("2. RuleIntegrationManager.sync_gui_to_loader() ã‚’å‘¼ã³å‡ºã™")  
    print("3. python loader.py ã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«åæ˜ ")

if __name__ == "__main__":
    main()
