import os
import csv
import chardet
import pandas as pd
import tkinter as tk
from tkinter import filedialog, messagebox, scrolledtext
import re

def detect_encoding(file_path):
    for enc in ['cp932', 'shift_jis']:
        try:
            with open(file_path, 'r', encoding=enc) as f:
                f.read(10)
            return enc, 1.0
        except UnicodeDecodeError:
            pass
    
    with open(file_path, 'rb') as f:
        raw_data = f.read(1024 * 10)
        result = chardet.detect(raw_data)
    return result['encoding'], result['confidence']

def detect_delimiter_and_types_revised(file_path, encoding):
    delimiter = 'N/A'
    data_types = ['N/A']
    fallback_delimiters = [',', '\t', ';', '|', ' ']
    try:
        with open(file_path, 'r', encoding=encoding) as f:
            sample = f.read(1024 * 5)
            if sample:
                try:
                    dialect = csv.Sniffer().sniff(sample)
                    delimiter = dialect.delimiter
                except csv.Error:
                    pass
        df = None
        current_delimiter = delimiter if delimiter != 'N/A' else None
        for delim in ([current_delimiter] if current_delimiter else []) + fallback_delimiters:
            try:
                df = pd.read_csv(file_path, sep=delim, encoding=encoding, nrows=10, engine='python', on_bad_lines='skip', header=None)
                if len(df.columns) > 1:
                    delimiter = delim
                    break
                else:
                    df = None
            except Exception:
                df = None
        if df is not None:
            inferred_types = [pd.api.types.infer_dtype(df[col], skipna=True) for col in df.columns]
            data_types = inferred_types
        return delimiter, data_types
    except UnicodeDecodeError:
        return 'N/A', ['N/A']
    except Exception:
        return 'N/A', ['N/A']

def analyze_irregular_file_robust(file_path, encoding, expected_columns, file_name):
    """ä¸è¦å‰‡ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’é ‘å¥ã«è§£æã™ã‚‹é–¢æ•°"""
    try:
        print(f"\nğŸ” åˆ†æé–‹å§‹: {file_name}")
        print("="*60)
        
        # 1. ã¾ãšãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€åˆã®æ•°è¡Œã‚’æ‰‹å‹•ã§èª­ã‚“ã§æ§‹é€ ã‚’ç¢ºèª
        with open(file_path, 'r', encoding=encoding) as f:
            first_line = f.readline().strip()
            second_line = f.readline().strip()
            third_line = f.readline().strip()
        
        print(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã‚µãƒ³ãƒ—ãƒ«:")
        print(f"   ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ: {first_line[:80]}{'...' if len(first_line) > 80 else ''}")
        print(f"   ãƒ‡ãƒ¼ã‚¿è¡Œ1: {second_line[:80]}{'...' if len(second_line) > 80 else ''}")
        print(f"   ãƒ‡ãƒ¼ã‚¿è¡Œ2: {third_line[:80]}{'...' if len(third_line) > 80 else ''}")
        
        # 2. ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®è§£æï¼ˆæœŸå¾…åˆ—æ•°ã‚’åŸºæº–ã«æœ€é©ãªåŒºåˆ‡ã‚Šæ–‡å­—ã‚’é¸æŠï¼‰
        print(f"\nğŸ¯ ãƒ˜ãƒƒãƒ€ãƒ¼è§£æ (æœŸå¾…åˆ—æ•°: {expected_columns})")
        header_columns = None
        header_delimiter = None
        best_match_diff = float('inf')
        
        for delim in ['\t', ' ', r'\s+', ',', ';']:
            try:
                if delim == r'\s+':
                    # æ­£è¦è¡¨ç¾ã®å ´åˆã¯æ‰‹å‹•ã§åˆ†å‰²
                    parts = re.split(r'\s+', first_line)
                    parts = [p.strip() for p in parts if p.strip()]
                else:
                    parts = first_line.split(delim)
                    parts = [p.strip() for p in parts if p.strip()]
                
                column_count = len(parts)
                delim_name = {'\\t': 'ã‚¿ãƒ–', ' ': 'ã‚¹ãƒšãƒ¼ã‚¹', r'\\s+': 'æ­£è¦è¡¨ç¾', ',': 'ã‚«ãƒ³ãƒ', ';': 'ã‚»ãƒŸã‚³ãƒ­ãƒ³'}.get(delim, delim)
                
                print(f"   {delim_name:8}: {column_count:3}åˆ—", end="")
                
                # æœŸå¾…åˆ—æ•°ãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã«æœ€ã‚‚è¿‘ã„çµæœã‚’é¸ã¶
                if expected_columns != 'N/A':
                    diff = abs(column_count - expected_columns)
                    if diff < best_match_diff and column_count > 10:
                        best_match_diff = diff
                        header_columns = column_count
                        header_delimiter = delim
                        print(f" â† BEST MATCH (å·®åˆ†: {diff})")
                    else:
                        print(f" (å·®åˆ†: {diff})")
                else:
                    # æœŸå¾…åˆ—æ•°ãŒãªã„å ´åˆã¯å¾“æ¥é€šã‚Š
                    if column_count > 10:
                        header_columns = column_count
                        header_delimiter = delim
                        print(f" â† SELECTED")
                        break
                    else:
                        print("")
                        
            except Exception as e:
                print(f"   {delim:8}: ERROR - {e}")
                continue
        
        # 3. ãƒ‡ãƒ¼ã‚¿è¡Œã®è§£æï¼ˆæœŸå¾…åˆ—æ•°ã«åˆã‚ã›ã¦æœ€é©ãªæ–¹æ³•ã‚’é¸æŠï¼‰
        print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿è¡Œè§£æ")
        data_columns = None
        data_delimiter = None
        data_types = ['N/A']
        best_data_diff = float('inf')
        
        # è¤‡æ•°ã®æ–¹æ³•ã§ãƒ‡ãƒ¼ã‚¿è¡Œã‚’èª­ã¿è¾¼ã‚€
        methods = [
            # æ–¹æ³•1: pandas with quoting=csv.QUOTE_NONE (æ­£è¦è¡¨ç¾åŒºåˆ‡ã‚Š)
            ('æ­£è¦è¡¨ç¾åŒºåˆ‡ã‚Š', lambda: pd.read_csv(file_path, sep=r'\s+', encoding=encoding, 
                               engine='python', skiprows=1, nrows=5, header=None,
                               quoting=csv.QUOTE_NONE, on_bad_lines='skip')),
            # æ–¹æ³•2: pandas with tab separator
            ('ã‚¿ãƒ–åŒºåˆ‡ã‚Š', lambda: pd.read_csv(file_path, sep='\t', encoding=encoding, 
                               engine='python', skiprows=1, nrows=5, header=None,
                               quoting=csv.QUOTE_NONE, on_bad_lines='skip')),
            # æ–¹æ³•3: æ‰‹å‹•åˆ†å‰²
            ('æ‰‹å‹•è§£æ', lambda: manual_parse_data_lines(file_path, encoding)),
            # æ–¹æ³•4: pandas with comma separator  
            ('ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š', lambda: pd.read_csv(file_path, sep=',', encoding=encoding, 
                               engine='python', skiprows=1, nrows=5, header=None,
                               quoting=csv.QUOTE_NONE, on_bad_lines='skip')),
        ]
        
        df = None
        method_used = "None"
        
        for method_name, method_func in methods:
            try:
                test_df = method_func()
                if test_df is not None and len(test_df.columns) > 5:
                    test_columns = len(test_df.columns)
                    
                    # æœŸå¾…åˆ—æ•°ã«æœ€ã‚‚è¿‘ã„çµæœã‚’é¸ã¶
                    if expected_columns != 'N/A':
                        diff = abs(test_columns - expected_columns)
                        print(f"   {method_name:12}: {test_columns:3}åˆ—", end="")
                        if diff < best_data_diff:
                            best_data_diff = diff
                            df = test_df
                            data_columns = test_columns
                            method_used = method_name
                            print(f" â† BEST MATCH (å·®åˆ†: {diff})")
                        else:
                            print(f" (å·®åˆ†: {diff})")
                    else:
                        # æœŸå¾…åˆ—æ•°ãŒãªã„å ´åˆã¯æœ€åˆã«æˆåŠŸã—ãŸæ–¹æ³•ã‚’ä½¿ç”¨
                        print(f"   {method_name:12}: {test_columns:3}åˆ—", end="")
                        if df is None:
                            df = test_df
                            data_columns = test_columns
                            method_used = method_name
                            print(f" â† SELECTED")
                        else:
                            print("")
                else:
                    print(f"   {method_name:12}: FAILED (åˆ—æ•°ä¸è¶³)")
                            
            except Exception as e:
                print(f"   {method_name:12}: ERROR - {str(e)[:30]}...")
                continue
        
        # ãƒ‡ãƒ¼ã‚¿å‹æ¨å®š
        if df is not None:
            data_types = [pd.api.types.infer_dtype(df[col], skipna=True) for col in df.columns]
            print(f"\nğŸ“‹ ãƒ‡ãƒ¼ã‚¿å‹æ¨å®šå®Œäº†: {len(data_types)}ç¨®é¡ã®å‹ã‚’æ¤œå‡º")
        
        # 4. çµæœã®æ±ºå®šï¼ˆæœŸå¾…åˆ—æ•°ã‚’æœ€å„ªå…ˆï¼‰
        print(f"\nğŸ“ˆ è§£æçµæœã‚µãƒãƒªãƒ¼")
        if expected_columns != 'N/A':
            # æœŸå¾…åˆ—æ•°ãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã‚’æ­£è§£ã¨ã™ã‚‹
            actual_columns = expected_columns
            print(f"   æœŸå¾…åˆ—æ•°: {expected_columns}")
            print(f"   ãƒ˜ãƒƒãƒ€ãƒ¼æ¤œå‡ºåˆ—æ•°: {header_columns}")  
            print(f"   ãƒ‡ãƒ¼ã‚¿æ¤œå‡ºåˆ—æ•°: {data_columns}")
            print(f"   â†’ æ¡ç”¨åˆ—æ•°: {actual_columns} (æœŸå¾…å€¤ã‚’æ¡ç”¨)")
            
            # ä¸è¦å‰‡æ€§ã®åˆ¤å®š
            if header_columns and abs(header_columns - expected_columns) > 5:
                is_irregular = 'Yes (Header Column Mismatch)'
                print(f"   ğŸš¨ ä¸è¦å‰‡åˆ¤å®š: ãƒ˜ãƒƒãƒ€ãƒ¼åˆ—æ•°ä¸ä¸€è‡´")
            elif data_columns and abs(data_columns - expected_columns) > 5:
                is_irregular = 'Yes (Data Column Mismatch)'  
                print(f"   ğŸš¨ ä¸è¦å‰‡åˆ¤å®š: ãƒ‡ãƒ¼ã‚¿åˆ—æ•°ä¸ä¸€è‡´")
            else:
                is_irregular = 'Yes (Known Irregular - Resolved)'
                print(f"   âœ… ä¸è¦å‰‡åˆ¤å®š: æ—¢çŸ¥ã®ä¸è¦å‰‡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè§£æ±ºæ¸ˆã¿ï¼‰")
        else:
            # æœŸå¾…åˆ—æ•°ãŒãªã„å ´åˆ
            actual_columns = data_columns if data_columns else header_columns
            is_irregular = 'Yes (Unknown Structure)'
            print(f"   âš ï¸  ä¸è¦å‰‡åˆ¤å®š: æ§‹é€ ä¸æ˜")
        
        delimiter_desc = f"Header: {header_delimiter} ({header_columns if header_columns else 'N/A'} cols), Data: {method_used} ({data_columns if data_columns else 'N/A'} cols)"
        
        return delimiter_desc, data_types, actual_columns, is_irregular
        
    except Exception as e:
        print(f"å…¨ä½“çš„ãªè§£æã‚¨ãƒ©ãƒ¼: {e}")
        return 'Analysis Failed', ['N/A'], 0, 'Yes (Analysis Error)'

def manual_parse_data_lines(file_path, encoding):
    """æ‰‹å‹•ã§ãƒ‡ãƒ¼ã‚¿è¡Œã‚’è§£æ"""
    try:
        with open(file_path, 'r', encoding=encoding) as f:
            lines = f.readlines()[1:6]  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦5è¡Œå–å¾—
        
        parsed_data = []
        for line in lines:
            # è¤‡æ•°ã®ç©ºç™½æ–‡å­—ã§åˆ†å‰²
            parts = re.split(r'\s+', line.strip())
            parts = [p for p in parts if p]  # ç©ºæ–‡å­—åˆ—ã‚’é™¤å»
            parsed_data.append(parts)
        
        if parsed_data:
            # æœ€å¤§åˆ—æ•°ã‚’å–å¾—
            max_cols = max(len(row) for row in parsed_data)
            # DataFrameã«å¤‰æ›ï¼ˆæ¬ æå€¤ã¯NaNã§åŸ‹ã‚ã‚‹ï¼‰
            df_data = []
            for row in parsed_data:
                padded_row = row + [None] * (max_cols - len(row))
                df_data.append(padded_row)
            
            df = pd.DataFrame(df_data)
            return df
        
    except Exception as e:
        print(f"æ‰‹å‹•è§£æã‚¨ãƒ©ãƒ¼: {e}")
        return None

def analyze_files(file_paths):
    results = []
    known_irregular = {
        'ZS58MONTH.csv': {'columns': 38},
        'ZS61KDAY.csv': {'columns': 68},
    }
    for file_path in file_paths:
        file_name = os.path.basename(file_path)
        is_irregular = 'No'
        expected_columns = 'N/A'
        
        encoding, confidence = detect_encoding(file_path)

        if file_name in known_irregular:
            expected_columns = known_irregular[file_name]['columns']
            
            # æ–°ã—ã„é ‘å¥ãªè§£æé–¢æ•°ã‚’ä½¿ç”¨
            delimiter_final, data_types, actual_columns, is_irregular = analyze_irregular_file_robust(
                file_path, encoding, expected_columns, file_name
            )
                        
        else:
            delimiter_final, data_types = detect_delimiter_and_types_revised(file_path, encoding)
            actual_columns = len(data_types)
            if delimiter_final not in [',', '\t', 'N/A']:
                is_irregular = 'Yes (Unusual Delimiter)'

        if expected_columns != 'N/A' and actual_columns != expected_columns:
            if is_irregular == 'No':  # ã¾ã ä¸è¦å‰‡ã¨åˆ¤å®šã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿
                is_irregular = 'Yes (Column Mismatch)'

        types_str = ", ".join(f"{t}" for t in data_types)  # å…¨ã¦ã®å‹ã‚’è¡¨ç¤º
            
        results.append({
            'File Path': file_path,
            'Irregular': is_irregular,
            'Expected Columns': expected_columns,
            'Actual Columns': actual_columns,
            'Delimiter': delimiter_final,
            'Encoding': encoding,
            'Data Types': types_str
        })
    return results

def select_files():
    file_paths = filedialog.askopenfilenames(
        title="ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        filetypes=[("CSV files", "*.csv")]
    )
    if file_paths:
        run_analysis(file_paths)

def run_analysis(file_paths):
    result_text.delete(1.0, tk.END)
    result_text.insert(tk.END, "åˆ†æä¸­...\n")
    root.update()  # UIã®æ›´æ–°
    
    # ã‚¿ãƒ¼ãƒŸãƒŠãƒ«å‡ºåŠ›ã‚’GUIã«ã‚‚ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¹
    class TextRedirector:
        def __init__(self, widget):
            self.widget = widget
        
        def write(self, text):
            self.widget.insert(tk.END, text)
            self.widget.see(tk.END)  # è‡ªå‹•ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
            root.update()  # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
        
        def flush(self):
            pass
    
    # æ¨™æº–å‡ºåŠ›ã‚’GUIã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
    import sys
    old_stdout = sys.stdout
    sys.stdout = TextRedirector(result_text)
    
    try:
        print("="*80)
        print("CSV FILE ANALYSIS REPORT - SQLiteæ ¼ç´å‰ãƒã‚§ãƒƒã‚¯")
        print("="*80)
        
        results = analyze_files(file_paths)
        
        print("\n" + "="*80)
        print("SUMMARY REPORT")
        print("="*80)
        
        if results:
            for i, result in enumerate(results, 1):
                print(f"\n[ãƒ•ã‚¡ã‚¤ãƒ« {i}] {os.path.basename(result['File Path'])}")
                print("-" * 50)
                
                # SQLiteæ ¼ç´ã«é‡è¦ãªæƒ…å ±ã‚’å¼·èª¿è¡¨ç¤º
                if result['Irregular'] != 'No':
                    print(f"âš ï¸  IRREGULAR FILE: {result['Irregular']}")
                else:
                    print("âœ… REGULAR FILE")
                    
                print(f"ğŸ“Š åˆ—æ•°: æœŸå¾…={result['Expected Columns']}, å®Ÿéš›={result['Actual Columns']}")
                print(f"ğŸ”¤ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {result['Encoding']}")
                print(f"ğŸ“ åŒºåˆ‡ã‚Šæ–‡å­—: {result['Delimiter']}")
                
                # SQLiteæ ¼ç´æ™‚ã®æ³¨æ„äº‹é …
                if result['Irregular'] != 'No':
                    print("ğŸš¨ SQLiteæ ¼ç´æ™‚ã®æ³¨æ„:")
                    if 'Column Mismatch' in result['Irregular']:
                        print("   - åˆ—æ•°ä¸ä¸€è‡´ã®ãŸã‚ã€ã‚¹ã‚­ãƒ¼ãƒå®šç¾©è¦ç¢ºèª")
                    if 'Header/Data Mismatch' in result['Irregular']:
                        print("   - ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ãƒ‡ãƒ¼ã‚¿ã§æ§‹é€ ãŒç•°ãªã‚Šã¾ã™")
                    if 'regex' in result['Delimiter']:
                        print("   - æ­£è¦è¡¨ç¾åŒºåˆ‡ã‚Šæ–‡å­—ä½¿ç”¨ã€ãƒ‘ãƒ¼ã‚¹å‡¦ç†è¦æ³¨æ„")
                    print("   - æ‰‹å‹•ã§ã®ã‚¹ã‚­ãƒ¼ãƒå®šç¾©ã‚’æ¨å¥¨")
                else:
                    print("âœ… SQLiteæ ¼ç´: æ¨™æº–çš„ãªå‡¦ç†ã§å•é¡Œãªã—")
                
                # ãƒ‡ãƒ¼ã‚¿å‹ã‚µãƒãƒªãƒ¼ï¼ˆé‡è¦ãªå‹ã®ã¿æŠœç²‹ï¼‰
                types_list = result['Data Types'].split(', ')
                type_counts = {}
                for t in types_list:
                    type_counts[t] = type_counts.get(t, 0) + 1
                
                print("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿å‹ã‚µãƒãƒªãƒ¼:")
                for dtype, count in sorted(type_counts.items(), key=lambda x: x[1], reverse=True):
                    print(f"   {dtype}: {count}åˆ—")
                
        print("\n" + "="*80)
        print("ANALYSIS COMPLETED")
        print("="*80)
        messagebox.showinfo("å®Œäº†", "è©³ç´°ãªåˆ†æçµæœã‚’ã”ç¢ºèªãã ã•ã„ã€‚\nã‚¿ãƒ¼ãƒŸãƒŠãƒ«å‡ºåŠ›ã«é‡è¦ãªæƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚")
        
    except Exception as e:
        print(f"\nâŒ ERROR: {e}")
        messagebox.showerror("ã‚¨ãƒ©ãƒ¼", f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    finally:
        # æ¨™æº–å‡ºåŠ›ã‚’å…ƒã«æˆ»ã™
        sys.stdout = old_stdout

# ãƒ¡ã‚¤ãƒ³ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®è¨­å®š
root = tk.Tk()
root.title("ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼")
root.geometry("800x600")

# ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®ä½œæˆ
frame = tk.Frame(root, padx=10, pady=10)
frame.pack(fill=tk.BOTH, expand=True)

select_button = tk.Button(frame, text="ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦åˆ†æé–‹å§‹", command=select_files, font=("Arial", 12))
select_button.pack(pady=10)

result_text = scrolledtext.ScrolledText(frame, wrap=tk.WORD, width=90, height=30, font=("Courier New", 10))
result_text.pack(fill=tk.BOTH, expand=True)

# GUIã®ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—é–‹å§‹
root.mainloop()